# Aesthetic Adaption
### Implementation of a deep learning model that can adapt an existing work to resemble original aesthetic of any artist.

## Methodology
A deep learning model that can adapt an existing work to resemble the original aesthetic of any artist is called "Neural Style Transfer". NST is a computer vision technique that combines the content of one image with the style of another image, to create a new image that preserves the content of the original image while adopting the artistic style of a reference image. 

The technique involves training a deep neural network to separate the content and style features of images. The network consists of two parts: a "content" network that extracts the high-level features of an image, and a "style" network that captures the texture and color patterns of a style image. The two networks are then combined to generate a new image that has the content of the original image but with the style of the reference image. \
Refer this paper on [A Neural Algorithm of Artistic Style](https://arxiv.org/pdf/1508.06576.pdf)

## Implementation (in PyTorch)
Ensure you have the following dependencies
```
torch >= 1.11.0+cu113
torchvision >= 0.12.0+cu113
Pillow
argparse
```
Run the code as follows
```
python neuralstyletransfer.py content.jpg style.jpg
```
where ```content.jpg``` and ```style.jpg``` refer to the original reference image and artistic style image respectively. You can test with any content and style image of your choice by changing the argument path in the command line

Note : Hyperparameters ```alpha``` and ```beta``` control the amount of style and content in the target image. 
* Increasing the ratio ```alpha/beta``` increases the retention of content structure in the target image
* Decreasing the ratio ```alpha/beta``` increases the retention of style layout in the target image

## Results (Demo Images)
![generated_stack-1.png](/results/generated_stack-1.png)
![generated_stack-2.png](/results/generated_stack-2.png)

## Pros
* Uniqueness : Uniquely combines the content of one image and style of another. User can provide their own custom combination of a content image and style image to generate a stylized reference image.
* Diverse Style transfer : Transfers the style of a famous artist to any image, allowing for the creation of custom art in the style of a particular artist and vise versa i.e a given image can be transferred to the style of many famous artists.
* Fast and Efficient : No need to train memory-intensive CNN Models unlike the GAN (particularly cGAN) approach for Neural Style Transfer. The model weights remain freezed and only the input image is optimized according to the content and style features
* Commercial Applications : Outputs are visually appealing and realistic, making it suitable for use in advertising and design industry.
* Transfer Learning : The features learned by the style transfer model can be transferred and used as a starting point for other computer vision tasks such as image segmentation or classification.
## Cons
* Computational scalability : The training process can take several hours or even days, depending on the size of the input images and the complexity of the desired style. The model needs to be trained everytime for each artistic style image which is time-consuming and resource-intensive. It cannot be scaled efficiently to several style images without compromising on the computational time.
* Non-Tunable output : Neural style transfer makes it difficult to control the output after the training. The model needs to be optimized for every level of style content in the image. This is because the model learns the style from the reference image, but does not have a clear understanding of the artistic rules and conventions that govern the style. This can be mitigated by complex GAN models which can learn the style rules from multiple artists making its outputs diverse and scalable.
* Hyperparameters : Needs to be manually tuned to generate the desired mix of content and style in the target image.
* Subjectivity : The quality of the output generated by Neural style transfer is subjective and dependent on the user's preferences. This means that what one person finds aesthetically pleasing, another may not.

## Alternate Solutions
There are several variations of Neural Style Transfer, but one of the most common approaches is to use a generative adversarial network (GAN), specifically a conditional GAN (cGAN), that conditions on the original image and generates a new image that has the desired artistic style. The GAN is trained with a loss function that encourages the generated image to match the style of the reference image while preserving the content of the original image.

